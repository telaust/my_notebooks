{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch import functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# буду использовать MNIST в качестве датасета\n",
    "transform = transforms.Compose( [transforms.ToTensor(), transforms.Normalize( (0.13,), (0.31,) )] )\n",
    "\n",
    "train_data = torchvision.datasets.MNIST(root='./data', \n",
    "                                        train=True, \n",
    "                                        download=False, \n",
    "                                        transform=transform)\n",
    "\n",
    "test_data = torchvision.datasets.MNIST(root='./data', \n",
    "                                       train=False, \n",
    "                                       download=False, \n",
    "                                       transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=4, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, inchannels, outchannels, stride=1):\n",
    "        super(ResBlock, self).__init__()\n",
    "        \n",
    "        self.stride = stride\n",
    "        self.conv1 = nn.Conv2d(in_channels=inchannels, \n",
    "                               out_channels=outchannels, kernel_size=3, stride=self.stride)\n",
    "        self.conv2 = nn.Conv2d(in_channels=outchannels, \n",
    "                               out_channels=outchannels, kernel_size=3, stride=self.stride)\n",
    "        \n",
    "        self.bn = nn.BatchNorm2d(num_features=outchannels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn(self.relu(out))\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn(out) # думаю, можно без этого \n",
    "        out += identity # тут надо \"объединить\" вход и аппроксмирующую ф-ию\n",
    "        \n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return nn.Sequential( out )\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, inchannels, n_layers, layer_comb, n_classes=10):\n",
    "        \"\"\"\n",
    "        layer_comb : лист, например, для 18слойной сети - это [2, 2, 2, 2]\n",
    "        \"\"\"\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        self.inchannels = inchannels\n",
    "        \n",
    "        # начальные слои, еще до ухода в глубину\n",
    "        self.conv1 = nn.Conv2d(in_channels=inchannels, \n",
    "                               out_channels=64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn = nn.BatchNorm2d(64) \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.conv2_x = self.make_layer(outchannels=64,  n_resblocks=layer_comb[0])\n",
    "        self.conv3_x = self.make_layer(outchannels=128, n_resblocks=layer_comb[1], stride=2)\n",
    "        self.conv4_x = self.make_layer(outchannels=256, n_resblocks=layer_comb[2], stride=2)\n",
    "        self.conv5_x = self.make_layer(outchannels=512, n_resblocks=layer_comb[3], stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=(1, 1))\n",
    "        self.fc = nn.Linear(1000, n_classes)\n",
    "        \n",
    "\n",
    "    ###----- надо доработать! ----------------------------------------\n",
    "    def make_layer(self, outchannels, n_resblocks, stride=1):\n",
    "        \n",
    "        layers = []\n",
    "        \n",
    "        for _ in range(n_resblocks):\n",
    "            layers.append(ResBlock(self.inchannels, outchannels, stride))\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn(self.relu(x))\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.conv2_x(x) # TODO\n",
    "        x = self.conv3_x(x) # TODO\n",
    "        x = self.conv4_x(x) # TODO\n",
    "        x = self.conv5_x(x) # TODO\n",
    "        \n",
    "        x = self.avgpool(x) \n",
    "        x = nn.Flatten(x) # flat it before fully connected\n",
    "        x = self.fc(x) \n",
    "        x = F.softmax(x) # на конце сглаживаем максимум как написано в статье\n",
    "        \n",
    "        return x\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResBlock(1, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (24) must match the size of tensor b (28) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-d26d4e54b16f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# feed to model , forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-a19f8dc644d3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# думаю, можно без этого\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0midentity\u001b[0m \u001b[0;31m# тут надо \"объединить\" вход и аппроксмирующую ф-ию\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (24) must match the size of tensor b (28) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adadelta(model.parameters(), lr=0.01)\n",
    "for epoch in range(6):\n",
    "    \n",
    "    for b_idx, (data, target) in enumerate(train_loader):\n",
    "        # zero initialization of gradients\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        # feed to model , forward pass\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out, target)\n",
    "    \n",
    "        # backprop\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        if b_idx % 1000 == 0 and i != 0:\n",
    "            print(\"epoch is {} and loss is {}\".format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
