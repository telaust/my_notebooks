{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import unicodedata \n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_letters = string.ascii_letters + \" .,;'\"\n",
    "# n_letters = len(all_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decrease dimension\n",
    "all_letters = string.ascii_lowercase # use it\n",
    "n_letters = len(all_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting uncode surnames to ascii\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "def findFiles(path): return glob.glob(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_names = {}\n",
    "all_categories = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_names(infile):\n",
    "    with open(infile, encoding=\"utf-8\") as file:\n",
    "        lines = file.readlines()\n",
    "        \n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "    \n",
    "# # Read a file and split into lines\n",
    "# def readLines(filename):\n",
    "#     lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "#     return [unicodeToAscii(line) for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bana', 'bano', 'barca', 'baroa', 'bascal']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_names(\"data/names/Spanish.txt\")[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in findFiles(\"data/names/*.txt\"):\n",
    "    cat = os.path.splitext(os.path.basename(filename))[0]\n",
    "    all_categories.append(cat)\n",
    "    names = read_names(filename)\n",
    "    category_names[cat] = names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_categories = len(all_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turning words to tensors\n",
    "\n",
    "def letter_to_index(letter):\n",
    "    return all_letters.index(letter)\n",
    "\n",
    "def name_to_tensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters) # initially zero tensor; 1 batch at a time\n",
    "    for ind, letter in enumerate(line):\n",
    "        tensor[ind][0][letter_to_index(letter)] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 26])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_to_tensor(\"hello\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        # логарифм вероятности\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        \n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.softmax(self.i2o(combined))\n",
    "        \n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 128\n",
    "\n",
    "rnn = RNN(n_letters, n_hidden, n_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_possible(output):\n",
    "    top_cat, top_ind = torch.Tensor.topk(output, 1)\n",
    "    cat_i = top_ind[0].item()\n",
    "    \n",
    "    return all_categories[cat_i], cat_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define measure of erros \n",
    "criterion = nn.CrossEntropyLoss() # or NLLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "def randomTrainingExample():\n",
    "    category = randomChoice(all_categories)\n",
    "    line = randomChoice(category_names[category])\n",
    "    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
    "    line_tensor = name_to_tensor(line)\n",
    "    return category, line, category_tensor, line_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001 \n",
    "\n",
    "def train(category_tensor, line_tensor, lr):\n",
    "    # zero initialization\n",
    "    hidden = rnn.initHidden()\n",
    "    rnn.zero_grad()\n",
    "    \n",
    "    for i in range(line_tensor.size(0)):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "    \n",
    "    loss = criterion(output, category_tensor)\n",
    "    loss.backward()\n",
    "    \n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(-lr, p.grad.data)\n",
    "\n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epoches = 20 # it seems 100_000 not enough\n",
    "losses = [] # in order to accumulate losses over training\n",
    "\n",
    "for ep in range(n_epoches):\n",
    "    cat, line, cat_tensor, line_tensor = randomTrainingExample()\n",
    "    output, loss = train(cat_tensor, line_tensor, lr)\n",
    "\n",
    "    losses.append(loss)\n",
    "#     if ep % 999 == 0 and ep != 0:\n",
    "#         guess, _ = most_possible(output)\n",
    "#         print(\"epoch: {.3f}%, loss is {.3f}, name is {}, guess is {}, correct is {}\".format((ep+1)*100/n_epoches, \n",
    "#                                                                                      loss,\n",
    "#                                                                                      line,\n",
    "#                                                                                      guess, \n",
    "#                                                                                      cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just return an output given a line\n",
    "def evaluate(line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    for i in range(line_tensor.size(0)):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_line, n_predictions=3):\n",
    "    input_line = input_line.lower() # because i decrease dimension\n",
    "    print('\\n> %s' % input_line)\n",
    "    with torch.no_grad():\n",
    "        output = evaluate(name_to_tensor(input_line))\n",
    "\n",
    "        # Get top N categories\n",
    "        topv, topi = output.topk(n_predictions, 1, True)\n",
    "        predictions = []\n",
    "\n",
    "        for i in range(n_predictions):\n",
    "            value = topv[0][i].item()\n",
    "            category_index = topi[0][i].item()\n",
    "            print('(%.2f) %s' % (value, all_categories[category_index]))\n",
    "            predictions.append([value, all_categories[category_index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> hinton\n",
      "(-1.51) English\n",
      "(-1.66) Scottish\n",
      "(-1.71) Irish\n"
     ]
    }
   ],
   "source": [
    "predict(\"hinton\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
