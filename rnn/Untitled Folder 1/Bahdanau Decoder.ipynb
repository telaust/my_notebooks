{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.functional import F\n",
    "import numpy as np\n",
    "\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.fr import French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, prob=0):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.prob = prob\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers=self.n_layers, dropout=prob, batch_first=True)\n",
    "        \n",
    "    def forward(self, inputs, hidden):\n",
    "        embedded = self.embedding(inputs)\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        \n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size=1):\n",
    "        return (torch.zeros(self.n_layers, batch_size, self.hidden_size),\n",
    "            torch.zeros(self.n_layers, batch_size, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, drop_prob=0):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, n_layers, dropout=drop_prob, batch_first=True)\n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "        # Embed input words\n",
    "        embedded = self.embedding(inputs)\n",
    "        # Pass the embedded word vectors into LSTM and return all outputs\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size=1):\n",
    "        return (torch.zeros(self.n_layers, batch_size, self.hidden_size, device=device),\n",
    "            torch.zeros(self.n_layers, batch_size, self.hidden_size, device=device),\n",
    "            torch.zeros(self.n_layers, batch_size, self.hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBahdanau(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, prob=0):\n",
    "        super(DecoderBahdanau, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_prob = prob\n",
    "        \n",
    "        # embedd decoder outputs\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        \n",
    "        self.fc_hidden = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.fc_encoder = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.FloatTensor(1, hidden_size)) # alpha ij ?\n",
    "        self.attn_combine = nn.Linear(2*self.hidden_size, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_prob)\n",
    "        self.lstm = nn.LSTM(2*self.hidden_size, self.hidden_size, batch_first=True)\n",
    "        self.classifier = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "    def forward(self, inputs, hidden, encoder_outputs):\n",
    "        encoder_outputs = encoder_outputs.squeeze()\n",
    "        embedded_decoder_inputs = self.embedding(inputs).view(1, -1)\n",
    "        embedded_decoder_inputs = self.dropout(embedded_decoder_inputs)\n",
    "        \n",
    "        # alignment score\n",
    "        x = torch.tanh(self.fc_hidden(hidden[0]) + self.fc_encoder(encoder_outputs))\n",
    "        alignment_score = x.bmm(self.weight.squeeze(2))\n",
    "        \n",
    "        # softmaxing alignment scores\n",
    "        attn_weights = F.softmax(alignment_score.view(1, -1), dim=1)\n",
    "        \n",
    "        # get context vector\n",
    "        context_vector = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "        # concat context vector & decoder embedded output/input into a single hidden state tensor\n",
    "        output = torch.cat((embedded_decoder_inputs, context_vector[0]), 1).unsqueeze(0)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        output = F.log_softmax(self.classifier(output[0]), dim=1)\n",
    "        \n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"fra.txt\", \"r+\") as file:\n",
    "    fra = [x[:-1] for x in file.readlines()] # remove \\n at the end of each line\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Go.\\tVa !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)',\n",
       " 'Hi.\\tSalut !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #509819 (Aiji)']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fra[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "en, fr = [], []\n",
    "\n",
    "for line in fra:\n",
    "    en.append(line.split('\\t')[0])\n",
    "    fr.append(line.split('\\t')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of training set\n",
    "len_train_examples = 100\n",
    "\n",
    "spacy_en, spacy_fr = English(), French()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_words, fr_words = Counter(), Counter()\n",
    "\n",
    "en_inputs, fr_inputs = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization\n",
    "for i in range(len_train_examples):\n",
    "    en_tokens = spacy_en(en[i])\n",
    "    fr_tokens = spacy_fr(fr[i])\n",
    "    \n",
    "    if len(en_tokens) == 0 or len(fr_tokens) == 0: # space or tab\n",
    "        continue\n",
    "    for token in en_tokens:\n",
    "        en_words.update([token.text.lower()])\n",
    "    en_inputs.append([token.text.lower() for token in en_tokens] + ['_EOS'])\n",
    "    \n",
    "    for token in fr_tokens:\n",
    "        fr_words.update([token.text.lower()])\n",
    "    fr_inputs.append([token.text.lower() for token in fr_tokens] + ['_EOS'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_words = ['_SOS', '_EOS', '_UNK'] + sorted(en_words, key=en_words.get, reverse=True)\n",
    "fr_words = ['_SOS', '_EOS', '_UNK'] + sorted(fr_words, key=fr_words.get, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_i2w = {index:word for index, word in enumerate(en_words)}\n",
    "fr_i2w = {index:word for index, word in enumerate(fr_words)}\n",
    "\n",
    "en_w2i = {word:index for index, word in enumerate(en_words)}\n",
    "fr_w2i = {word:index for index, word in enumerate(fr_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Enlish & French sentences to their token indices\n",
    "for i in range(len(en_inputs)):\n",
    "    en_sentence = en_inputs[i]\n",
    "    fr_sentence = fr_inputs[i]\n",
    "    \n",
    "    en_inputs[i] = [en_w2i[word] for word in en_sentence]\n",
    "    fr_inputs[i] = [fr_w2i[word] for word in fr_sentence]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "lr = 0.001\n",
    "hidden_size = 256\n",
    "epoches = 3\n",
    "teacher_forcing_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderLSTM(len(en_words), hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = DecoderBahdanau(hidden_size, len(fr_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=lr)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence is  [9, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([9, 3, 1])\n",
      "dim of inp is  3\n",
      "sentence is  [27, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([27,  3,  1])\n",
      "dim of inp is  3\n",
      "sentence is  [27, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([27,  3,  1])\n",
      "dim of inp is  3\n",
      "sentence is  [28, 4, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([28,  4,  1])\n",
      "dim of inp is  3\n",
      "sentence is  [28, 4, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([28,  4,  1])\n",
      "dim of inp is  3\n",
      "sentence is  [39, 10, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([39, 10,  1])\n",
      "dim of inp is  3\n",
      "sentence is  [40, 4, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([40,  4,  1])\n",
      "dim of inp is  3\n",
      "sentence is  [41, 4, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([41,  4,  1])\n",
      "dim of inp is  3\n",
      "sentence is  [42, 4, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([42,  4,  1])\n",
      "dim of inp is  3\n",
      "sentence is  [43, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([43,  3,  1])\n",
      "dim of inp is  3\n",
      "sentence is  [20, 4, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([20,  4,  1])\n",
      "dim of inp is  3\n",
      "sentence is  [20, 4, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([20,  4,  1])\n",
      "dim of inp is  3\n",
      "sentence is  [20, 4, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([20,  4,  1])\n",
      "dim of inp is  3\n",
      "sentence is  [29, 4, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([29,  4,  1])\n",
      "dim of inp is  3\n",
      "sentence is  [29, 4, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([29,  4,  1])\n",
      "dim of inp is  3\n",
      "sentence is  [9, 21, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 9, 21,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [9, 21, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 9, 21,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [9, 21, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 9, 21,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [30, 4, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([30,  4,  1])\n",
      "dim of inp is  3\n",
      "sentence is  [30, 4, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([30,  4,  1])\n",
      "dim of inp is  3\n",
      "sentence is  [6, 44, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 6, 44,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [6, 31, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 6, 31,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [6, 11, 4, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 6, 11,  4,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [6, 11, 4, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 6, 11,  4,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [6, 11, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 6, 11,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [45, 7, 4, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([45,  7,  4,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [32, 4, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([32,  4,  1])\n",
      "dim of inp is  3\n",
      "sentence is  [32, 4, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([32,  4,  1])\n",
      "dim of inp is  3\n",
      "sentence is  [17, 4, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([17,  4,  1])\n",
      "dim of inp is  3\n",
      "sentence is  [17, 4, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([17,  4,  1])\n",
      "dim of inp is  3\n",
      "sentence is  [17, 4, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([17,  4,  1])\n",
      "dim of inp is  3\n",
      "sentence is  [17, 4, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([17,  4,  1])\n",
      "dim of inp is  3\n",
      "sentence is  [46, 47, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([46, 47,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [9, 22, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 9, 22,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [9, 22, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 9, 22,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [9, 22, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 9, 22,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [15, 12, 4, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([15, 12,  4,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [15, 12, 4, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([15, 12,  4,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [15, 12, 10, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([15, 12, 10,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [15, 12, 10, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([15, 12, 10,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [15, 12, 10, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([15, 12, 10,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [33, 23, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([33, 23,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [33, 23, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([33, 23,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [34, 18, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([34, 18,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [34, 18, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([34, 18,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [6, 35, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 6, 35,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [6, 35, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 6, 35,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [6, 48, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 6, 48,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [6, 36, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 6, 36,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [6, 36, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 6, 36,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [6, 49, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 6, 49,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [6, 50, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 6, 50,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [6, 51, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 6, 51,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [6, 24, 52, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 6, 24, 52,  3,  1])\n",
      "dim of inp is  5\n",
      "sentence is  [6, 24, 37, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 6, 24, 37,  3,  1])\n",
      "dim of inp is  5\n",
      "sentence is  [6, 24, 37, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 6, 24, 37,  3,  1])\n",
      "dim of inp is  5\n",
      "sentence is  [53, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([53,  3,  1])\n",
      "dim of inp is  3\n",
      "sentence is  [7, 8, 4, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([7, 8, 4, 1])\n",
      "dim of inp is  4\n",
      "sentence is  [7, 8, 4, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([7, 8, 4, 1])\n",
      "dim of inp is  4\n",
      "sentence is  [7, 8, 4, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([7, 8, 4, 1])\n",
      "dim of inp is  4\n",
      "sentence is  [7, 8, 4, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([7, 8, 4, 1])\n",
      "dim of inp is  4\n",
      "sentence is  [7, 8, 4, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([7, 8, 4, 1])\n",
      "dim of inp is  4\n",
      "sentence is  [7, 8, 4, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([7, 8, 4, 1])\n",
      "dim of inp is  4\n",
      "sentence is  [7, 8, 4, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([7, 8, 4, 1])\n",
      "dim of inp is  4\n",
      "sentence is  [7, 8, 4, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([7, 8, 4, 1])\n",
      "dim of inp is  4\n",
      "sentence is  [7, 8, 4, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([7, 8, 4, 1])\n",
      "dim of inp is  4\n",
      "sentence is  [25, 10, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([25, 10,  1])\n",
      "dim of inp is  3\n",
      "sentence is  [25, 10, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([25, 10,  1])\n",
      "dim of inp is  3\n",
      "sentence is  [25, 10, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([25, 10,  1])\n",
      "dim of inp is  3\n",
      "sentence is  [54, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([54,  3,  1])\n",
      "dim of inp is  3\n",
      "sentence is  [16, 31, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([16, 31,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [16, 11, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([16, 11,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [16, 11, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([16, 11,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [16, 11, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([16, 11,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [16, 11, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([16, 11,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [55, 56, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([55, 56,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [57, 4, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([57,  4,  1])\n",
      "dim of inp is  3\n",
      "sentence is  [5, 26, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 5, 26,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [5, 26, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 5, 26,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [5, 26, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 5, 26,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [5, 58, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 5, 58,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [5, 13, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 5, 13,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [5, 13, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 5, 13,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [5, 13, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 5, 13,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [5, 13, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 5, 13,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [5, 13, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 5, 13,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [5, 13, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 5, 13,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [5, 59, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 5, 59,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [5, 14, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 5, 14,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [5, 14, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 5, 14,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [5, 14, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 5, 14,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [5, 14, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 5, 14,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [5, 14, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 5, 14,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [5, 14, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([ 5, 14,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [60, 12, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([60, 12,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [19, 18, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([19, 18,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [19, 18, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([19, 18,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [19, 38, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([19, 38,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [19, 38, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([19, 38,  3,  1])\n",
      "dim of inp is  4\n",
      "sentence is  [61, 23, 3, 1]\n",
      "dim of hidden state is  3\n",
      "input is  tensor([61, 23,  3,  1])\n",
      "dim of inp is  4\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(en_inputs):\n",
    "    h = encoder.init_hidden()\n",
    "    print(\"sentence is \", sentence)\n",
    "\n",
    "    print(\"dim of hidden state is \", len(h))\n",
    "    inp = torch.tensor(sentence).squeeze(0)\n",
    "    print(\"input is \", inp)\n",
    "    print(\"dim of inp is \", inp.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input must have 3 dimensions, got 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-182-cf1c9ebf6075>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# preprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# first decodee input is '_SOS'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-177-da603c929aec>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, hidden)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# Pass the embedded word vectors into LSTM and return all outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNNBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[1;32m    521\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             result = _VF.lstm(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;31m# type: (Tensor, Tuple[Tensor, Tensor], Optional[Tensor]) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    143\u001b[0m             raise RuntimeError(\n\u001b[1;32m    144\u001b[0m                 'input must have {} dimensions, got {}'.format(\n\u001b[0;32m--> 145\u001b[0;31m                     expected_input_dim, input.dim()))\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             raise RuntimeError(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input must have 3 dimensions, got 2"
     ]
    }
   ],
   "source": [
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "for ep in range(epoches):\n",
    "    avg_loss = 0\n",
    "    \n",
    "    for i, sentence in enumerate(en_inputs):\n",
    "        loss = 0\n",
    "        \n",
    "        h = encoder.init_hidden()\n",
    "        \n",
    "        # clear gradients\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        \n",
    "        # preprocess\n",
    "        inp = torch.tensor(sentence).squeeze(0)\n",
    "        encoder_outputs, h = encoder(inp, h)\n",
    "        \n",
    "        # first decodee input is '_SOS'\n",
    "        decoder_input = torch.tensor([en_w2i['_SOS']])\n",
    "        # first decoder hidden state is the last encoder hidden state\n",
    "        decoder_hidden = h\n",
    "        \n",
    "        output = []\n",
    "        teacher_forcing = True if random.random() < teacher_forcing_prob else False\n",
    "        for ii in range(len(fr_inputs[i])):\n",
    "            decoder_output, decoder_hidden, attn_weights = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            \n",
    "            top_value, top_index = decoder_output.topk(1)\n",
    "            \n",
    "            if teacher_forcing:\n",
    "                decoder_input = torch.tensor([fr_inputs[i][ii]])\n",
    "                \n",
    "            else:\n",
    "                decoder_input = torch.tensor([top_index.item()])\n",
    "                \n",
    "            output.append(top_index.item())\n",
    "            \n",
    "            loss += F.nll_loss(decoder_output.view(1, -1), torch.tensor([fr_inputs[i][ii]]))\n",
    "            \n",
    "        # backprop\n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        \n",
    "        avg_loss += loss.item() / len(en_inputs)\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoder.init_hidden())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
